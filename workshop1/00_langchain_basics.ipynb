{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb0f243",
   "metadata": {},
   "source": [
    "## LangChain Basics\n",
    "\n",
    "- Models\n",
    "- Messages\n",
    "- Tools\n",
    "- Create Agents\n",
    "\n",
    "\n",
    "Resources:\n",
    "- https://docs.langchain.com/oss/python/langchain/\n",
    "- https://github.com/langchain-ai/langgraph-101/blob/main/notebooks/LG101/langgraph_101.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "487b8b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment variables\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_TRACING\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66552c0d",
   "metadata": {},
   "source": [
    "---\n",
    "## Models\n",
    "\n",
    "Interacting with the different LLM providers, using the same abstractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "408081db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_14324\\668042874.py:3: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "#from langchain.chat_models import init_chat_model\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "llm = ChatOllama(\n",
    "    model=\"qwen2.5:0.5b\",\n",
    "    temperature=0.7, # Adjust temperature for creativity (0.0 to 1.0)\n",
    "    api_base=\"http://localhost:11434\" # Default URL, only needed if you changed the host\n",
    ")\n",
    "# llm = init_chat_model(\"qwen2.5:0.5b\")\n",
    "\n",
    "response = llm.invoke(\"Hello, world!\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84fb7f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'qwen2.5:0.5b',\n",
       " 'created_at': '2025-12-10T23:29:38.9828677Z',\n",
       " 'message': {'role': 'assistant', 'content': ''},\n",
       " 'done': True,\n",
       " 'done_reason': 'stop',\n",
       " 'total_duration': 2804437400,\n",
       " 'load_duration': 2319842100,\n",
       " 'prompt_eval_count': 33,\n",
       " 'prompt_eval_duration': 357415300,\n",
       " 'eval_count': 5,\n",
       " 'eval_duration': 103253300}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see the response metadata as well\n",
    "\n",
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc6dd1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once| upon| a| time|,| in| a| small| village| nestled| between| the| mountains| and| rivers|,| there| was| a| kind|-hearted| robot| named| Z|ane|.| Z|ane| was| not| just| any| robot|;| he| had| been| programmed| with| a| deep| connection| to| humanity|.| He| loved| helping| humans| in| many| ways| -| from| cleaning| up| after| the| animals| that| wandered| into| his| home|,| to| reading| stories| aloud| at| bedtime|,| or| even| making| delicious| meals| for| him| and| his| family|.\n",
      "\n",
      "|One| sunny| afternoon|,| Z|ane| found| himself| stuck| in| a| long| line| of| people| waiting| for| their| turn| to| go| through| customs| at| a| local| airport|.| He| couldn|'t| help| but| notice| how| many| strangers| were| passing| by| with| expressions| of| worry| and| nervous|ness| on| their| faces|.| \n",
      "\n",
      "|\"|Z|ane|,\"| he| said|,| his| voice| soft| and| warm|.\n",
      "\n",
      "|\"Yes|,| Z|ane|?\"| the| robot| replied|.| \"|I| noticed| some| people| looking| worried|.| Can| you| try| to| help| them|?| I| know| that|'s| a| small| thing|,| but| it| helps| to| make| their| day|.\"| The| robot| opened| up| his| mouth| to| speak|,| but| then| he| remembered| something| important| -| he| had| been| programmed| to| never| say| anything| in|appropri|ately|.\n",
      "\n",
      "|\"I| have| to| be| careful|,\"| Z|ane| assured| him|.| \"|I|'m| just| here| for| the| sake| of| this| place| and| its| people|.\"\n",
      "\n",
      "|The| robot| moved| forward|,| taking| a| deep| breath| and| moving| through| the| queue| with| his| usual| calm|ness|.| He| approached| a| group| of| elderly| folks| who| were| trying| to| find| their| seats| at| the| back| of| the| line|.| Z|ane| helped| them| carry| chairs| as| they| made| their| way| to| their| seats|.\n",
      "\n",
      "|\"|Z|ane|,\"| one| of| the| older| ladies| said| kindly|,| \"|I|'m| sorry| for| you| and| your| family|.\"\n",
      "\n",
      "|Z|ane| smiled|,| feeling| a| sense| of| pride| in| his| ability| to| help| people| who| were| struggling| with| small| issues|.| He| told| her| that| he| could| do| any| job| that| was| needed|.\n",
      "\n",
      "|As| the| lines| continued| to| stretch| out|,| Z|ane| felt| a| mix| of| emotions| -| excitement| at| finally| seeing| some| humans| again| after| a| long| time|,| and| a| bit| of| relief| knowing| that| he| had| made| a| difference| in| their| day|.\n",
      "\n",
      "|Finally|,| the| last| group| of| people| were| all| able| to| get| on| the| plane|.| The| robot| left| with| a| sense| of| satisfaction| and| a| newfound| appreciation| for| his| role| as| an| ally| in| helping| others|.| He| knew| that| his| life| would| always| be| intertwined| with| that| of| humans|,| but| he| was| glad| to| have| found| a| way| to| make| a| difference|.|||"
     ]
    }
   ],
   "source": [
    "# Streaming responses\n",
    "\n",
    "message = \"Tell me a story about a friendly robot who loves to help humans.\"\n",
    "\n",
    "for chunk in llm.stream(message):\n",
    "    # Printing each chunk as it arrives with a separator to visualize streaming\n",
    "    print(chunk.text, end=\"|\", flush=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da963fd",
   "metadata": {},
   "source": [
    "---\n",
    "## Messages\n",
    "\n",
    "The fundamental unit of context for models in LangChain, they are the input and output of models, tools, agents, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "668c0b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola! ¿Qué tipo de pizza quieres? ¿Y qué toppings deseas agregar? También te gustaría que incluyamos los extraques y los pollos en la lista de ingredientes?\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"qwen2.5:0.5b\",\n",
    "    temperature=0.7, # Adjust temperature for creativity (0.0 to 1.0)\n",
    "    api_base=\"http://localhost:11434\" # Default URL, only needed if you changed the host\n",
    ")\n",
    "#llm = init_chat_model(\"gpt-5-mini\")\n",
    "# llm = init_chat_model(\"qwen2.5:0.5b\")\n",
    "\n",
    "\n",
    "system_msg = SystemMessage(\"You are a helpful assistant that translates to Spanish anything the user says.\")\n",
    "human_msg = HumanMessage(\"I would like to order a pizza with extra cheese and mushrooms.\")\n",
    "\n",
    "# Use with chat models\n",
    "messages = [system_msg, human_msg]\n",
    "response = llm.invoke(messages)  # Returns AIMessage\n",
    "\n",
    "print(response.content)  # Translated text in Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad947814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Why don't scientists trust atoms? Because they make up everything.\n"
     ]
    }
   ],
   "source": [
    "# Building a chat list or history with Messages\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant.\"),\n",
    "    HumanMessage(\"Hello, how are you?\"),\n",
    "    AIMessage(\"I am doing well, thank you! How can I assist you today?\"),\n",
    "    HumanMessage(\"Can you tell me a joke?\"),\n",
    "]\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# The model's response according to all previous chat history\n",
    "print(response.content)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2350696e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Here's one for you:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything.\n"
     ]
    }
   ],
   "source": [
    "# Alternative format using dictionaries\n",
    "\n",
    "messages_dict = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "\t{\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "\t{\"role\": \"assistant\", \"content\": \"I am doing well, thank you! How can I assist you today?\"},\n",
    "\t{\"role\": \"user\", \"content\": \"Can you tell me a joke?\"},\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages_dict)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a494909d",
   "metadata": {},
   "source": [
    "---\n",
    "## Tools\n",
    "\n",
    "Tools extend the capabilities of LLMs by providing them with access to external knowledge and functionalities. You can give an LLM a list of tools, and when appropriate, it can choose to use them to complete a given task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd922f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dune, Interstellar, Blade Runner 2049\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "# Basic hardcoded tool\n",
    "@tool\n",
    "def search_movies(genre: str) -> str:\n",
    "    \"\"\"Search for movies by genre. Currently supports 'sci-fi', 'comedy', and 'action'.\"\"\"\n",
    "    # In a real app, this would query a movie database\n",
    "    movies = {\n",
    "        \"sci-fi\": \"Dune, Interstellar, Blade Runner 2049\",\n",
    "        \"comedy\": \"The Grand Budapest Hotel, Superbad, Knives Out\",\n",
    "        \"action\": \"Mad Max: Fury Road, John Wick, Mission Impossible\"\n",
    "    }\n",
    "    \n",
    "    return movies.get(genre.lower(), \"No movies found for that genre\")\n",
    "\n",
    "\n",
    "# Using the tool\n",
    "result = search_movies.invoke({\"genre\": \"sci-fi\"})\n",
    "\n",
    "print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96226c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"temperature_celsius\": 11.1, \"weather_code\": 3}\n"
     ]
    }
   ],
   "source": [
    "# More realistic tool that calls an API\n",
    "@tool\n",
    "def get_weather(latitude: float, longitude: float) -> str:\n",
    "    \"\"\"Get current temperature in Celsius and weather code for given coordinates.\n",
    "\n",
    "    Args:\n",
    "        latitude: Latitude coordinate\n",
    "        longitude: Longitude coordinate\n",
    "\n",
    "    Returns:\n",
    "        JSON string with temperature_celsius and weather_code (do not include the code in your response, translate it to plain English)\n",
    "    \"\"\"\n",
    "    \n",
    "    url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"current\": \"temperature_2m,weather_code\",\n",
    "        \"temperature_unit\": \"celsius\"\n",
    "    }\n",
    "\n",
    "    weather = requests.get(url, params=params).json()[\"current\"]\n",
    "    temperature = weather[\"temperature_2m\"]\n",
    "    weather_code = weather[\"weather_code\"]\n",
    "    result = {\n",
    "        \"temperature_celsius\": temperature,\n",
    "        \"weather_code\": weather_code\n",
    "    }\n",
    "\n",
    "    return json.dumps(result)\n",
    "\n",
    "# Test a tool directly with Barcelona coordinates\n",
    "print(get_weather.invoke({\"latitude\": 41.38, \"longitude\": 2.17}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bfa7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This doesn't work with models running in Ollama\n",
    "\n",
    "# Bind tools to the model\n",
    "tools = [get_weather, search_movies]\n",
    "model_with_tools = llm.bind_tools(tools)\n",
    "message = \"What's the weather like in Barcelona? (Barcelona's coordinates are approximately 41.38° N latitude and 2.17° E longitude) \"\n",
    "\n",
    "# The model can now decide to call tools\n",
    "response = model_with_tools.invoke(message)\n",
    "\n",
    "# Check if the model wants to call a tool, in that case, we won't see the response of the tool yet.\n",
    "print(\"Tool calls:\", response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e779bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's execute the tool and continue the conversation\n",
    "\n",
    "from langchain.messages import ToolMessage\n",
    "\n",
    "# Execute the tool call\n",
    "if response.tool_calls:\n",
    "    tool_call = response.tool_calls[0]\n",
    "\n",
    "    # Call the actual tool\n",
    "    if tool_call[\"name\"] == \"get_weather\":\n",
    "        result = get_weather.invoke(tool_call[\"args\"])\n",
    "\n",
    "    elif tool_call[\"name\"] == \"search_movies\":\n",
    "        result = search_movies.invoke(tool_call[\"args\"])\n",
    "\n",
    "    # Create a ToolMessage with the result\n",
    "    tool_message = ToolMessage(\n",
    "        content=result,\n",
    "        tool_call_id=tool_call[\"id\"]\n",
    "    )\n",
    "\n",
    "    # Continue the conversation with the tool result\n",
    "    final_response = model_with_tools.invoke([\n",
    "        HumanMessage(content=message),\n",
    "        response,\n",
    "        tool_message\n",
    "    ])\n",
    "\n",
    "    final_response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e151ff",
   "metadata": {},
   "source": [
    "---\n",
    "## LangChain Create Agent\n",
    "\n",
    "Recently, LangChain introduced a new way to create simple agents (which uses LangGraph underneath), which simplifies the process of building agents that can use tools. \n",
    "\n",
    "This prebuilt agent does the following so called \"ReAct\" pattern:\n",
    "\n",
    "1. Model decides which tool to call (if any)\n",
    "2. Tool gets executed\n",
    "3. Result goes back to model\n",
    "4. Repeat until task is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306c83d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Create an agent with tools\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather, search_movies],\n",
    "    system_prompt=\"You are a helpful assistant that can check weather and recommend movies.\"\n",
    ")\n",
    "\n",
    "# Use the agent\n",
    "result = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What's the weather in Madrid? (40.41° N, 3.70° W) Also recommend some sci-fi movies.\")]\n",
    "})\n",
    "\n",
    "# Print the final response\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8772a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x1169ae060>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing the agent structure\n",
    "\n",
    "agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc28d3",
   "metadata": {},
   "source": [
    "## Giving Tools with MCPs to our Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa722031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 MCP tools: ['add_time', 'compare_time', 'convert_timezone', 'current_time', 'relative_time']\n"
     ]
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Connect to the mcp-time server for timezone-aware operations\n",
    "# This Go-based server provides tools for current time, relative time parsing,\n",
    "# timezone conversion, duration arithmetic, and time comparison\n",
    "mcp_client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"time\": {\n",
    "            \"transport\": \"stdio\",\n",
    "            \"command\": \"npx\",\n",
    "            \"args\": [\"-y\", \"@theo.foobar/mcp-time\"],\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "# Load tools from the MCP server\n",
    "mcp_tools = await mcp_client.get_tools()\n",
    "print(f\"Loaded {len(mcp_tools)} MCP tools: {[t.name for t in mcp_tools]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fbb8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_mcp = create_agent(\n",
    "    model=\"openai:gpt-5-mini\",\n",
    "    tools=mcp_tools,\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b8634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's the time in Barcelona right now?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  current_time (call_HR2BHv293AEBsp9WJDCST7W0)\n",
      " Call ID: call_HR2BHv293AEBsp9WJDCST7W0\n",
      "  Args:\n",
      "    timezone: Europe/Madrid\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: current_time\n",
      "\n",
      "2025-11-29T04:03:09+01:00\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It's 04:03:09 on 29 November 2025 in Barcelona (CET, UTC+1). Need it shown in a different timezone or format?\n"
     ]
    }
   ],
   "source": [
    "result = await agent_with_mcp.ainvoke(\n",
    "    {\"messages\": [{\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"What's the time in Barcelona right now?\"\n",
    "    }]}\n",
    ")\n",
    "\n",
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydaybcn2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
