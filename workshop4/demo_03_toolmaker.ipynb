{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkgWh1qm934C"
      },
      "source": [
        "# Demo 3: The Agent Toolmaker\n",
        "\n",
        "## Concept: Self-Modification / Hot-swapping\n",
        "\n",
        " We'll build an agent that can **create its own tools at runtime** - acquiring capabilities it didn't have 5 minutes ago.\n",
        "\n",
        "```\n",
        "Request ‚Üí Tool Missing ‚Üí LLM Writes Tool ‚Üí Hot-swap ‚Üí Request Fulfilled\n",
        "```\n",
        "\n",
        "### What We'll Build\n",
        "\n",
        "An agent that:\n",
        "1. Starts with basic math tools (add, subtract, multiply)\n",
        "2. Receives a request it can't handle (sentiment analysis)\n",
        "3. Detects the missing capability\n",
        "4. Writes a new tool using an LLM\n",
        "5. Hot-reloads the tool library\n",
        "6. Completes the original request\n",
        "\n",
        "### The Key Concept: Open-Endedness\n",
        "\n",
        "The system gains complexity with use. Each new tool persists, making the agent more capable over time.\n",
        "\n",
        "---\n",
        "\n",
        "### Related Papers\n",
        "\n",
        "- **Voyager**: An Open-Ended Embodied Agent with Large Language Models  \n",
        "  [arXiv:2305.16291](https://arxiv.org/abs/2305.16291)\n",
        "\n",
        "- **MetaGPT**: Meta Programming for A Multi-Agent Collaborative Framework  \n",
        "  [arXiv:2308.00352](https://arxiv.org/abs/2308.00352)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0ajygDH934D"
      },
      "source": [
        "## Setup\n",
        "\n",
        "You have three options for the LLM provider:\n",
        "\n",
        "### Option 1: OpenAI (Recommended)\n",
        "1. Get an API key from [platform.openai.com](https://platform.openai.com)\n",
        "2. Add secret `OPENAI_API_KEY` in Colab Secrets (key icon in sidebar)\n",
        "\n",
        "### Option 2: Google Gemini (FREE)\n",
        "1. Get a free API key from [Google AI Studio](https://aistudio.google.com/apikey)\n",
        "2. Add secret `GEMINI_API_KEY` in Colab Secrets\n",
        "3. In the next cell, comment out the OpenAI section and uncomment the Gemini section\n",
        "\n",
        "### Option 3: Groq (FREE - Very Fast)\n",
        "1. Get a free API key from [console.groq.com](https://console.groq.com)\n",
        "2. Add secret `GROQ_API_KEY` in Colab Secrets\n",
        "3. In the next cell, comment out the OpenAI section and uncomment the Groq section\n",
        "4. Uses Llama 3.1 model\n",
        "\n",
        "We'll also install TextBlob for sentiment analysis (which the agent will learn to use!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# OPTION 0: Ollama locally installed\n",
        "# ============================================================\n",
        "#!pip install ollama -q\n",
        "import ollama as client\n",
        "MODEL='qwen2.5:0.5b'      # ollama pull qwen2.5:0.5b\n",
        "MODEL='granite4:350m'     # ollama pull granite4:350m\n",
        "MODEL='granite4:1b'       # ollama pull granite4:1b\n",
        "MODEL='gemma3n:e2b'       # ollama pull gemma3n:e2b\n",
        "\n",
        "response = client.chat(model=MODEL, \n",
        "                       messages=[{'role': 'user', 'content': 'Hello, how are you?'}],\n",
        "                       options={ 'temperature': 1 },\n",
        "                      )\n",
        "\n",
        "print(response['message']['content'])\n",
        "print()\n",
        "print(\"Setup complete! Using Ollama\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRyMfiJd934D"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to\n",
            "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\brown.zip.\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
          ]
        }
      ],
      "source": [
        "# Install TextBlob dependencies (needed for all options)\n",
        "# !pip install textblob -q\n",
        "# !python -m textblob.download_corpora lite\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "\n",
        "# OPTION 0: OpenAI (Recommended - requires API key with credits)\n",
        "# ============================================================\n",
        "#!pip install ollama -q\n",
        "import ollama as client\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# OPTION 1: OpenAI (Recommended - requires API key with credits)\n",
        "# ============================================================\n",
        "# !pip install openai -q\n",
        "\n",
        "# from google.colab import userdata\n",
        "# from openai import OpenAI\n",
        "# import importlib\n",
        "# import re\n",
        "# import os\n",
        "\n",
        "# client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "\n",
        "# print(\"Setup complete! Using OpenAI\")\n",
        "\n",
        "# ============================================================\n",
        "# OPTION 2: Google Gemini (FREE - uncomment below, comment above)\n",
        "# ============================================================\n",
        "# !pip install google-generativeai -q\n",
        "#\n",
        "# from google.colab import userdata\n",
        "# import google.generativeai as genai\n",
        "# import importlib\n",
        "# import re\n",
        "# import os\n",
        "#\n",
        "# genai.configure(api_key=userdata.get('GEMINI_API_KEY'))\n",
        "#\n",
        "# # Wrapper class to make Gemini API compatible with OpenAI-style calls\n",
        "# class GeminiClient:\n",
        "#     def __init__(self):\n",
        "#         self._model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "#\n",
        "#     class _Completions:\n",
        "#         def __init__(self, model):\n",
        "#             self._model = model\n",
        "#\n",
        "#         def create(self, model=None, messages=None, temperature=0.7, **kwargs):\n",
        "#             prompt_parts = []\n",
        "#             for msg in messages:\n",
        "#                 role = msg.get('role', 'user')\n",
        "#                 content = msg.get('content', '')\n",
        "#                 if role == 'system':\n",
        "#                     prompt_parts.append(f\"Instructions: {content}\")\n",
        "#                 else:\n",
        "#                     prompt_parts.append(content)\n",
        "#\n",
        "#             prompt = \"\\n\\n\".join(prompt_parts)\n",
        "#\n",
        "#             response = self._model.generate_content(\n",
        "#                 prompt,\n",
        "#                 generation_config=genai.GenerationConfig(temperature=temperature)\n",
        "#             )\n",
        "#\n",
        "#             class Message:\n",
        "#                 def __init__(self, text):\n",
        "#                     self.content = text\n",
        "#\n",
        "#             class Choice:\n",
        "#                 def __init__(self, text):\n",
        "#                     self.message = Message(text)\n",
        "#\n",
        "#             class Response:\n",
        "#                 def __init__(self, text):\n",
        "#                     self.choices = [Choice(text)]\n",
        "#\n",
        "#             return Response(response.text)\n",
        "#\n",
        "#     @property\n",
        "#     def chat(self):\n",
        "#         class Chat:\n",
        "#             def __init__(chat_self):\n",
        "#                 chat_self.completions = GeminiClient._Completions(self._model)\n",
        "#         return Chat()\n",
        "#\n",
        "# client = GeminiClient()\n",
        "#\n",
        "# print(\"Setup complete! Using Google Gemini (FREE)\")\n",
        "\n",
        "# ============================================================\n",
        "# OPTION 3: Groq (FREE - very fast, uncomment below, comment above)\n",
        "# ============================================================\n",
        "# !pip install openai -q\n",
        "#\n",
        "# from google.colab import userdata\n",
        "# from openai import OpenAI\n",
        "# import importlib\n",
        "# import re\n",
        "# import os\n",
        "#\n",
        "# client = OpenAI(\n",
        "#     api_key=userdata.get('GROQ_API_KEY'),\n",
        "#     base_url=\"https://api.groq.com/openai/v1\"\n",
        "# )\n",
        "#\n",
        "# # IMPORTANT: When using Groq, change the model in API calls from\n",
        "# # \"gpt-4o-mini\" to \"openai/gpt-oss-20b\"\n",
        "#\n",
        "# print(\"Setup complete! Using Groq (FREE)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_wnpVmS934E"
      },
      "source": [
        "## Creating the Initial Tool Library\n",
        "\n",
        "We'll create a `tools.py` file that contains the agent's initial capabilities. This file will be **modified at runtime** when the agent learns new skills.\n",
        "\n",
        "Key components:\n",
        "- Individual tool functions\n",
        "- A `TOOLS` registry dictionary that maps names to functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gy2R--Sy934E"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created tools.py with basic math tools\n",
            "üì¶ Available tools: ['add', 'subtract', 'multiply']\n"
          ]
        }
      ],
      "source": [
        "# Create the initial tools module\n",
        "tools_code = '''\"\"\"Agent's tool library - can be extended at runtime!\"\"\"\n",
        "\n",
        "def add(a: float, b: float) -> float:\n",
        "    \"\"\"Add two numbers together.\"\"\"\n",
        "    return a + b\n",
        "\n",
        "def subtract(a: float, b: float) -> float:\n",
        "    \"\"\"Subtract b from a.\"\"\"\n",
        "    return a - b\n",
        "\n",
        "def multiply(a: float, b: float) -> float:\n",
        "    \"\"\"Multiply two numbers together.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "# Registry of available tools\n",
        "TOOLS = {\n",
        "    \"add\": add,\n",
        "    \"subtract\": subtract,\n",
        "    \"multiply\": multiply,\n",
        "}\n",
        "'''\n",
        "\n",
        "# Write the tools file\n",
        "with open(\"tools.py\", \"w\") as f:\n",
        "    f.write(tools_code)\n",
        "\n",
        "print(\"‚úÖ Created tools.py with basic math tools\")\n",
        "\n",
        "# Import the tools module\n",
        "import tools\n",
        "print(f\"üì¶ Available tools: {list(tools.TOOLS.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91TVwoEP934E"
      },
      "source": [
        "## The Toolmaker Agent\n",
        "\n",
        "This is our self-improving agent. It has three key capabilities:\n",
        "\n",
        "1. **`execute_tool`**: Run a tool by name (raises `ToolNotFoundError` if missing)\n",
        "2. **`create_new_tool`**: Ask the LLM to write a new tool function\n",
        "3. **`add_tool_to_library`**: Modify `tools.py` and hot-reload it\n",
        "\n",
        "The magic is in `importlib.reload()` - it reloads a Python module without restarting the interpreter!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XfUvyZa934E"
      },
      "outputs": [],
      "source": [
        "class ToolNotFoundError(Exception):\n",
        "    \"\"\"Raised when the agent tries to use a tool that doesn't exist.\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "class ToolmakerAgent:\n",
        "    \"\"\"\n",
        "    An agent that can create its own tools at runtime.\n",
        "\n",
        "    When a tool is missing, it uses an LLM to write the tool,\n",
        "    adds it to tools.py, and hot-reloads the module.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reload_tools()\n",
        "\n",
        "    def reload_tools(self):\n",
        "        \"\"\"Hot-reload the tools module to pick up new tools.\"\"\"\n",
        "        import tools\n",
        "        importlib.reload(tools)\n",
        "        self.tools = tools.TOOLS\n",
        "        print(f\"üîÑ Tools reloaded: {list(self.tools.keys())}\")\n",
        "\n",
        "    def execute_tool(self, tool_name: str, **kwargs):\n",
        "        \"\"\"\n",
        "        Execute a tool by name.\n",
        "\n",
        "        Args:\n",
        "            tool_name: Name of the tool to execute\n",
        "            **kwargs: Arguments to pass to the tool\n",
        "\n",
        "        Returns:\n",
        "            The tool's return value\n",
        "\n",
        "        Raises:\n",
        "            ToolNotFoundError: If the tool doesn't exist\n",
        "        \"\"\"\n",
        "        if tool_name not in self.tools:\n",
        "            raise ToolNotFoundError(f\"Tool '{tool_name}' not found. Available: {list(self.tools.keys())}\")\n",
        "        return self.tools[tool_name](**kwargs)\n",
        "\n",
        "    def create_new_tool(self, tool_name: str, description: str) -> str:\n",
        "        \"\"\"\n",
        "        Ask the LLM to write a new tool function.\n",
        "\n",
        "        Args:\n",
        "            tool_name: Name for the new function\n",
        "            description: What the function should do\n",
        "\n",
        "        Returns:\n",
        "            The generated Python function code as a string\n",
        "        \"\"\"\n",
        "        prompt = f\"\"\"Create a Python function called `{tool_name}` that does the following:\n",
        "                    {description}\n",
        "\n",
        "                    Requirements:\n",
        "                    - Use simple, standard libraries (textblob for NLP is available via `from textblob import TextBlob`)\n",
        "                    - Include a docstring explaining what the function does\n",
        "                    - Include type hints for parameters and return value\n",
        "                    - Return a clear, structured result (dict for complex data)\n",
        "                    - Handle edge cases gracefully\n",
        "\n",
        "                    Return ONLY the function code, no imports (they should be inside the function if needed), no explanation.\n",
        "                    \"\"\"\n",
        "\n",
        "        response = client.chat(\n",
        "            model=MODEL, \n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            options={ 'temperature': 0 }, # Deterministic for reliable code\n",
        "        )\n",
        "        func_code = response.message.content\n",
        "\n",
        "        # response = client.chat.completions.create(\n",
        "        #     model=\"gpt-4o-mini\",\n",
        "        #     messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        #     temperature=0  # Deterministic for reliable code\n",
        "        # )\n",
        "        #func_code = response.choices[0].message.content\n",
        "\n",
        "        # Clean up code block markers if present\n",
        "        if \"```python\" in func_code:\n",
        "            func_code = func_code.split(\"```python\")[1].split(\"```\")[0]\n",
        "        elif \"```\" in func_code:\n",
        "            func_code = func_code.split(\"```\")[1].split(\"```\")[0]\n",
        "\n",
        "        return func_code.strip()\n",
        "\n",
        "    def _extract_imports(self, code: str) -> tuple[list[str], str]:\n",
        "        \"\"\"\n",
        "        Extract import statements from code and return them separately.\n",
        "\n",
        "        Args:\n",
        "            code: Python code that may contain import statements\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (list of import lines, code without imports)\n",
        "        \"\"\"\n",
        "        lines = code.split('\\n')\n",
        "        imports = []\n",
        "        other_lines = []\n",
        "\n",
        "        for line in lines:\n",
        "            stripped = line.strip()\n",
        "            if stripped.startswith('import ') or stripped.startswith('from '):\n",
        "                # Use stripped version to avoid indentation issues\n",
        "                imports.append(stripped)\n",
        "            else:\n",
        "                other_lines.append(line)\n",
        "\n",
        "        # Remove leading empty lines from other_lines\n",
        "        while other_lines and not other_lines[0].strip():\n",
        "            other_lines.pop(0)\n",
        "\n",
        "        return imports, '\\n'.join(other_lines)\n",
        "\n",
        "    def add_tool_to_library(self, tool_name: str, func_code: str):\n",
        "        \"\"\"\n",
        "        Add a new tool to tools.py and hot-reload.\n",
        "\n",
        "        This modifies the tools.py file to:\n",
        "        1. Extract any imports and add them to the top of the file\n",
        "        2. Add the new function definition\n",
        "        3. Register it in the TOOLS dictionary\n",
        "\n",
        "        Args:\n",
        "            tool_name: Name of the new tool\n",
        "            func_code: The Python function code (may include imports)\n",
        "        \"\"\"\n",
        "        # Extract imports from the generated code\n",
        "        new_imports, func_code_clean = self._extract_imports(func_code)\n",
        "\n",
        "        # Read current tools.py\n",
        "        with open(\"tools.py\", \"r\") as f:\n",
        "            current_code = f.read()\n",
        "\n",
        "        # If there are new imports, add them after the docstring\n",
        "        if new_imports:\n",
        "            # Find the end of the docstring\n",
        "            docstring_end = current_code.find('\"\"\"', 3) + 3  # Find closing \"\"\"\n",
        "\n",
        "            # Get existing imports to avoid duplicates\n",
        "            existing_imports = set()\n",
        "            for line in current_code.split('\\n'):\n",
        "                stripped = line.strip()\n",
        "                if stripped.startswith('import ') or stripped.startswith('from '):\n",
        "                    existing_imports.add(stripped)\n",
        "\n",
        "            # Filter out duplicate imports\n",
        "            unique_new_imports = [imp for imp in new_imports if imp not in existing_imports]\n",
        "\n",
        "            if unique_new_imports:\n",
        "                import_block = '\\n'.join(unique_new_imports)\n",
        "                current_code = (\n",
        "                    current_code[:docstring_end] +\n",
        "                    '\\n' + import_block +\n",
        "                    current_code[docstring_end:]\n",
        "                )\n",
        "                print(f\"üì• Added imports: {unique_new_imports}\")\n",
        "\n",
        "        # Add the new function before the TOOLS registry\n",
        "        tools_dict_line = \"# Registry of available tools\"\n",
        "\n",
        "        new_code = current_code.replace(\n",
        "            tools_dict_line,\n",
        "            f\"{func_code_clean}\\n\\n{tools_dict_line}\"\n",
        "        )\n",
        "\n",
        "        # Update TOOLS dict to include the new function\n",
        "        new_code = new_code.replace(\n",
        "            \"TOOLS = {\",\n",
        "            f'TOOLS = {{\\n    \"{tool_name}\": {tool_name},'\n",
        "        )\n",
        "\n",
        "        # Write the modified file\n",
        "        with open(\"tools.py\", \"w\") as f:\n",
        "            f.write(new_code)\n",
        "\n",
        "        print(f\"‚úÖ Added '{tool_name}' to tools.py\")\n",
        "\n",
        "        # Hot-reload to make the new tool available\n",
        "        self.reload_tools()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzGKqZnT934F"
      },
      "source": [
        "## Testing the Agent's Existing Tools\n",
        "\n",
        "Let's verify the agent works with its built-in math tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7Nxx-Dru934F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Tools reloaded: ['add', 'subtract', 'multiply']\n",
            "\n",
            "üßÆ Testing existing tools:\n",
            "  add(5, 3) = 8\n",
            "  subtract(10, 4) = 6\n",
            "  multiply(7, 8) = 56\n"
          ]
        }
      ],
      "source": [
        "import importlib\n",
        "import ollama\n",
        "# Create the agent\n",
        "agent = ToolmakerAgent()\n",
        "\n",
        "print(\"\\nüßÆ Testing existing tools:\")\n",
        "print(f\"  add(5, 3) = {agent.execute_tool('add', a=5, b=3)}\")\n",
        "print(f\"  subtract(10, 4) = {agent.execute_tool('subtract', a=10, b=4)}\")\n",
        "print(f\"  multiply(7, 8) = {agent.execute_tool('multiply', a=7, b=8)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wWI1SP6934F"
      },
      "source": [
        "## The Self-Improvement Demo\n",
        "\n",
        "Now let's ask the agent to do something it **can't do yet**: sentiment analysis.\n",
        "\n",
        "Watch what happens:\n",
        "1. The agent tries to use `analyze_sentiment`\n",
        "2. It fails with `ToolNotFoundError`\n",
        "3. The agent writes a new tool using the LLM\n",
        "4. It adds the tool to its library\n",
        "5. It successfully completes the request!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LTYN8cm934F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "ü§î Let's ask for sentiment analysis...\n",
            "============================================================\n",
            "\n",
            "‚ùå Tool 'analyze_sentiment' not found. Available: ['add', 'subtract', 'multiply']\n",
            "\n",
            "üîß Agent is creating a new tool...\n",
            "\n",
            "üìù Generated function:\n",
            "----------------------------------------\n",
            "3\n",
            "import textblob\n",
            "\n",
            "def analyze_sentiment(text: str) -> dict:\n",
            "    \"\"\"\n",
            "    Analyze the sentiment of a given text string using TextBlob library.\n",
            "\n",
            "    Parameters:\n",
            "    - text (str): The text to analyze for sentiment.\n",
            "\n",
            "    Returns:\n",
            "    - dict: A dictionary containing the polarity, subjectivity,\n",
            "            and a label indicating if it's positive, negative or neutral.\n",
            "    \"\"\"\n",
            "\n",
            "    # Use TextBlob to get the sentiment analysis\n",
            "    blob = textblob.TextBlob(text)\n",
            "    \n",
            "    # Convert polarity from 0-1 to -1-1 for consistency in our function\n",
            "    blob.polarity = -blob.sentiment.polarity\n",
            "\n",
            "    # Return the result as a dictionary, where 'polarity', 'subjectivity', and 'label' are fields\n",
            "    return {\n",
            "        \"polarity\": blob.polarity,\n",
            "        \"subjectivity\": blob.sentiment.subjectivity,\n",
            "        \"label\": \"positive\" if blob.sentiment.polarity > 0 else (\"negative\" if blob.sentiment.polarity < 0 else \"neutral\")\n",
            "    }\n",
            "----------------------------------------\n",
            "\n",
            "üíæ Adding to tools.py...\n",
            "üì• Added imports: ['import textblob']\n",
            "‚úÖ Added 'analyze_sentiment' to tools.py\n",
            "üîÑ Tools reloaded: ['analyze_sentiment', 'add', 'subtract', 'multiply']\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ü§î Let's ask for sentiment analysis...\")\n",
        "print(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "try:\n",
        "    # This will fail - the tool doesn't exist yet!\n",
        "    result = agent.execute_tool(\"analyze_sentiment\", text=\"I love this workshop!\")\n",
        "    print(f\"Result: {result}\")\n",
        "\n",
        "except ToolNotFoundError as e:\n",
        "    print(f\"‚ùå {e}\")\n",
        "    print(\"\\nüîß Agent is creating a new tool...\\n\")\n",
        "\n",
        "    # The agent creates the tool itself!\n",
        "    func_code = agent.create_new_tool(\n",
        "        tool_name=\"analyze_sentiment\",\n",
        "        description=\"\"\"Analyze the sentiment of a text string.\n",
        "                    Use the TextBlob library for analysis.\n",
        "                    Return a dictionary with:\n",
        "                    - 'polarity': float from -1 (negative) to 1 (positive)\n",
        "                    - 'subjectivity': float from 0 (objective) to 1 (subjective)\n",
        "                    - 'label': string 'positive', 'negative', or 'neutral' based on polarity\"\"\"\n",
        "    )\n",
        "\n",
        "    print(\"üìù Generated function:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(func_code)\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Add to the tool library\n",
        "    print(\"\\nüíæ Adding to tools.py...\")\n",
        "    agent.add_tool_to_library(\"analyze_sentiment\", func_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c26tWXwz934F"
      },
      "source": [
        "## Using the Newly Created Tool\n",
        "\n",
        "The agent now has sentiment analysis capabilities! Let's test it on various texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4rLN3Fa8934F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üéâ Testing the newly created tool:\n",
            "\n",
            "üìù \"The weather in Barcelona is absolutely perfect today!\"\n",
            "   ‚Üí {'polarity': -1.0, 'subjectivity': 1.0, 'label': 'positive'}\n",
            "\n",
            "üìù \"I can't believe how amazing La Sagrada Familia looks.\"\n",
            "   ‚Üí {'polarity': -0.6000000000000001, 'subjectivity': 0.9, 'label': 'positive'}\n",
            "\n",
            "üìù \"This PyDay workshop is incredibly inspiring!\"\n",
            "   ‚Üí {'polarity': -0.625, 'subjectivity': 1.0, 'label': 'positive'}\n",
            "\n",
            "üìù \"Python is a programming language.\"\n",
            "   ‚Üí {'polarity': -0.0, 'subjectivity': 0.0, 'label': 'neutral'}\n",
            "\n",
            "üìù \"I'm so frustrated with these bugs!\"\n",
            "   ‚Üí {'polarity': 0.875, 'subjectivity': 0.2, 'label': 'negative'}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nüéâ Testing the newly created tool:\\n\")\n",
        "\n",
        "test_texts = [\n",
        "    \"The weather in Barcelona is absolutely perfect today!\",\n",
        "    \"I can't believe how amazing La Sagrada Familia looks.\",\n",
        "    \"This PyDay workshop is incredibly inspiring!\",\n",
        "    \"Python is a programming language.\",\n",
        "    \"I'm so frustrated with these bugs!\"\n",
        "]\n",
        "\n",
        "for text in test_texts:\n",
        "    result = agent.execute_tool(\"analyze_sentiment\", text=text)\n",
        "    print(f'üìù \"{text}\"')\n",
        "    print(f\"   ‚Üí {result}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBRqlO2S934G"
      },
      "source": [
        "## Inspecting the Modified Tools\n",
        "\n",
        "Let's look at how `tools.py` was modified. The agent literally rewrote its own code!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qlN0lCn3934G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÑ Current tools.py content:\n",
            "============================================================\n",
            "\"\"\"Agent's tool library - can be extended at runtime!\"\"\"\n",
            "import textblob\n",
            "\n",
            "def add(a: float, b: float) -> float:\n",
            "    \"\"\"Add two numbers together.\"\"\"\n",
            "    return a + b\n",
            "\n",
            "def subtract(a: float, b: float) -> float:\n",
            "    \"\"\"Subtract b from a.\"\"\"\n",
            "    return a - b\n",
            "\n",
            "def multiply(a: float, b: float) -> float:\n",
            "    \"\"\"Multiply two numbers together.\"\"\"\n",
            "    return a * b\n",
            "\n",
            "3\n",
            "\n",
            "def analyze_sentiment(text: str) -> dict:\n",
            "    \"\"\"\n",
            "    Analyze the sentiment of a given text string using TextBlob library.\n",
            "\n",
            "    Parameters:\n",
            "    - text (str): The text to analyze for sentiment.\n",
            "\n",
            "    Returns:\n",
            "    - dict: A dictionary containing the polarity, subjectivity,\n",
            "            and a label indicating if it's positive, negative or neutral.\n",
            "    \"\"\"\n",
            "\n",
            "    # Use TextBlob to get the sentiment analysis\n",
            "    blob = textblob.TextBlob(text)\n",
            "    \n",
            "    # Convert polarity from 0-1 to -1-1 for consistency in our function\n",
            "    blob.polarity = -blob.sentiment.polarity\n",
            "\n",
            "    # Return the result as a dictionary, where 'polarity', 'subjectivity', and 'label' are fields\n",
            "    return {\n",
            "        \"polarity\": blob.polarity,\n",
            "        \"subjectivity\": blob.sentiment.subjectivity,\n",
            "        \"label\": \"positive\" if blob.sentiment.polarity > 0 else (\"negative\" if blob.sentiment.polarity < 0 else \"neutral\")\n",
            "    }\n",
            "\n",
            "# Registry of available tools\n",
            "TOOLS = {\n",
            "    \"analyze_sentiment\": analyze_sentiment,\n",
            "    \"add\": add,\n",
            "    \"subtract\": subtract,\n",
            "    \"multiply\": multiply,\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"üìÑ Current tools.py content:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "with open(\"tools.py\", \"r\") as f:\n",
        "    print(f.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gf7OB6T934G"
      },
      "source": [
        "## Bonus: Creating Another Tool\n",
        "\n",
        "Let's demonstrate that the agent can keep learning! Let's ask it for a word counting tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cBe6kY8n934G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "üÜï Let's teach the agent to count words...\n",
            "============================================================\n",
            "\n",
            "‚ùå Tool 'count_words' not found. Available: ['analyze_sentiment', 'add', 'subtract', 'multiply']\n",
            "\n",
            "üîß Creating word count tool...\n",
            "\n",
            "üìù Generated function:\n",
            "from textblob import TextBlob\n",
            "\n",
            "def count_words(text: str) -> dict:\n",
            "    \"\"\"\n",
            "    Count words in a given text.\n",
            "    \n",
            "    Parameters:\n",
            "    - text (str): The text string to analyze.\n",
            "    \n",
            "    Returns:\n",
            "    - dict: A dictionary containing the following keys:\n",
            "        total_words: Total number of unique words\n",
            "        unique_words: Number of unique words\n",
            "        char_count: Total characters excluding spaces\n",
            "    \"\"\"\n",
            "    # Initialize a TextBlob object for the text\n",
            "    blob = TextBlob(text)\n",
            "    \n",
            "    # Convert all words to lowercase and filter out punctuation\n",
            "    word_counts = {word.lower(): count for word, count in blob.words}\n",
            "    \n",
            "    return {\n",
            "        'total_words': len(word_counts),\n",
            "        'unique_words': len(word_counts),\n",
            "        'char_count': len(''.join(blob.words))\n",
            "    }\n",
            "\n",
            "# Function to check the correctness of the solution\n",
            "def check_solution():\n",
            "    sample_text = \"The quick brown fox jumps over the lazy dog.\"\n",
            "    result = count_words(sample_text)\n",
            "    print(result)\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    # Example usage: Check with a predefined text string\n",
            "    check_solution()\n",
            "\n",
            "üì• Added imports: ['from textblob import TextBlob']\n",
            "‚úÖ Added 'count_words' to tools.py\n",
            "üîÑ Tools reloaded: ['count_words', 'analyze_sentiment', 'add', 'subtract', 'multiply']\n",
            "\n",
            "üß™ Testing word count tool:\n",
            "\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müß™ Testing word count tool:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m test_text = \u001b[33m\"\u001b[39m\u001b[33mThe quick brown fox jumps over the lazy dog. The dog was very lazy.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m result = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcount_words\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mText: \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResult: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mToolmakerAgent.execute_tool\u001b[39m\u001b[34m(self, tool_name, **kwargs)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tool_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tools:\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ToolNotFoundError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTool \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtool_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not found. Available: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.tools.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtool_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\python\\pydaybcn2025-workshop-code-evolution\\tools.py:61\u001b[39m, in \u001b[36mcount_words\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     58\u001b[39m blob = TextBlob(text)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Convert all words to lowercase and filter out punctuation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m word_counts = {word.lower(): count \u001b[38;5;28;01mfor\u001b[39;00m word, count \u001b[38;5;129;01min\u001b[39;00m blob.words}\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     64\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtotal_words\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(word_counts),\n\u001b[32m     65\u001b[39m     \u001b[33m'\u001b[39m\u001b[33munique_words\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(word_counts),\n\u001b[32m     66\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mchar_count\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m.join(blob.words))\n\u001b[32m     67\u001b[39m }\n",
            "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üÜï Let's teach the agent to count words...\")\n",
        "print(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "try:\n",
        "    result = agent.execute_tool(\"count_words\", text=\"Hello world\")\n",
        "except ToolNotFoundError as e:\n",
        "    print(f\"‚ùå {e}\")\n",
        "    print(\"\\nüîß Creating word count tool...\\n\")\n",
        "\n",
        "    func_code = agent.create_new_tool(\n",
        "        tool_name=\"count_words\",\n",
        "        description=\"\"\"Count words in a text string.\n",
        "Return a dictionary with:\n",
        "- 'total_words': total number of words\n",
        "- 'unique_words': number of unique words (case-insensitive)\n",
        "- 'char_count': total characters (excluding spaces)\"\"\"\n",
        "    )\n",
        "\n",
        "    print(\"üìù Generated function:\")\n",
        "    print(func_code)\n",
        "    print()\n",
        "\n",
        "    agent.add_tool_to_library(\"count_words\", func_code)\n",
        "\n",
        "# Now use it\n",
        "print(\"\\nüß™ Testing word count tool:\\n\")\n",
        "test_text = \"The quick brown fox jumps over the lazy dog. The dog was very lazy.\"\n",
        "result = agent.execute_tool(\"count_words\", text=test_text)\n",
        "print(f'Text: \"{test_text}\"')\n",
        "print(f\"Result: {result}\")\n",
        "\n",
        "print(f\"\\nüì¶ Final tool inventory: {list(agent.tools.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4hzys3G934G"
      },
      "source": [
        "## Key Takeaways\n",
        "\n",
        "### What We Learned\n",
        "\n",
        "1. **Open-Ended Systems**: The agent grows more capable with each interaction. It started with 3 tools and now has 5 (or more!).\n",
        "\n",
        "2. **Hot-Swapping with `importlib.reload()`**: Python lets us reload modules at runtime without restarting. This enables true self-modification.\n",
        "\n",
        "3. **Tool Discovery Pattern**: When a capability is missing, the agent:\n",
        "   - Detects the gap (ToolNotFoundError)\n",
        "   - Synthesizes a solution (LLM writes code)\n",
        "   - Integrates it (add to tools.py)\n",
        "   - Persists it (the tool exists for future use)\n",
        "\n",
        "### Safety Considerations\n",
        "\n",
        "‚ö†Ô∏è **This is powerful but dangerous!**\n",
        "\n",
        "In production, you must:\n",
        "- **Sandbox generated code**: Run in isolated environments (containers, VMs)\n",
        "- **Validate before execution**: Check for dangerous operations (file deletion, network access, etc.)\n",
        "- **Human review**: Critical tools should be reviewed before deployment\n",
        "- **Audit trail**: Log all self-modifications for debugging and security\n",
        "- **Rollback capability**: Keep backups of previous tool versions\n",
        "\n",
        "### Real-World Applications\n",
        "\n",
        "- **Voyager (Minecraft AI)**: Creates new skills as it explores the game world\n",
        "- **Auto-GPT style agents**: Expand capabilities based on task requirements\n",
        "- **Code assistants**: Learn new patterns from codebases they interact with\n",
        "- **Domain-specific agents**: Acquire specialized tools for niche tasks\n",
        "\n",
        "### The Big Picture\n",
        "\n",
        "We've seen three levels of code self-improvement:\n",
        "\n",
        "1. **Demo 1 (Self-Healer)**: Fix broken code using error feedback\n",
        "2. **Demo 2 (Evolution)**: Optimize code through selection and mutation\n",
        "3. **Demo 3 (Toolmaker)**: Create entirely new capabilities on demand\n",
        "\n",
        "Together, these patterns point toward **truly adaptive software** - systems that improve, evolve, and grow with use.\n",
        "\n",
        "---\n",
        "\n",
        "**Thank you for attending this workshop!** üéâ\n",
        "\n",
        "Questions? Let's discuss!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "langgraph-agents-pyday-bcn",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
